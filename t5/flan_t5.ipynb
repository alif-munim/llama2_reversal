{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMfr3kI8VRgIVMNx26FxfAE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alif-munim/llm-reversal/blob/main/t5/flan_t5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T_Zxdzc-DYwp",
        "outputId": "ef0fe587-d181-41d0-adb4-cccc00854f31"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.10/dist-packages (4.35.0)\n",
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.10/dist-packages (0.14.1)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.14.6)\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.10/dist-packages (0.4.1)\n",
            "Requirement already satisfied: rouge_score in /usr/local/lib/python3.10/dist-packages (0.1.2)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.1.99)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.17.3)\n",
            "Collecting huggingface_hub\n",
            "  Using cached huggingface_hub-0.18.0-py3-none-any.whl (301 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (3.12.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.31.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.4.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (4.66.1)\n",
            "Requirement already satisfied: torch!=1.12.0,>=1.10 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.1.0+cu118)\n",
            "Requirement already satisfied: accelerate>=0.20.3 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.24.1)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.6)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.18.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge_score) (3.8.1)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.16.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.5.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.20.3->transformers[torch]) (5.9.5)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (3.3.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2023.7.22)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (3.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (3.1.2)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (2.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (1.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3.post1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch!=1.12.0,>=1.10->transformers[torch]) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch!=1.12.0,>=1.10->transformers[torch]) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "pip install transformers[torch] tokenizers datasets evaluate rouge_score sentencepiece huggingface_hub --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the necessary libraries\n",
        "import nltk\n",
        "from datasets import load_dataset\n",
        "import evaluate\n",
        "import numpy as np\n",
        "from transformers import T5Tokenizer, DataCollatorForSeq2Seq\n",
        "from transformers import T5ForConditionalGeneration, Seq2SeqTrainingArguments, Seq2SeqTrainer"
      ],
      "metadata": {
        "id": "j56vua69Darv"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and split the dataset\n",
        "dataset = load_dataset(\"lberglund/reversal_curse\")"
      ],
      "metadata": {
        "id": "M96VsZF4DfAT"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the tokenizer, model, and data collator\n",
        "model_name = \"google/flan-t5-small\"\n",
        "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
        "model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
        "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MC-rZDQUDflO",
        "outputId": "11f3c8ea-b1a2-47c4-fd64-c9a54a4084df"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We prefix our tasks with \"answer the question\"\n",
        "prefix = \"complete the sentence: \"\n",
        "\n",
        "# Define our preprocessing function\n",
        "def preprocess_function(examples):\n",
        "    \"\"\"Add prefix to the sentences, tokenize the text, and set the labels\"\"\"\n",
        "    # The \"inputs\" are the tokenized answer:\n",
        "    inputs = [prefix + doc for doc in examples[\"prompt\"]]\n",
        "    model_inputs = tokenizer(inputs, max_length=128, truncation=True)\n",
        "\n",
        "    # The \"labels\" are the tokenized outputs:\n",
        "    labels = tokenizer(text_target=examples[\"completion\"], max_length=512, truncation=True)\n",
        "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "    return model_inputs\n",
        "\n",
        "# Map the preprocessing function across our dataset\n",
        "tokenized_dataset = dataset.map(preprocess_function, batched=True)"
      ],
      "metadata": {
        "id": "SoHyvMRGDh5m"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up Rouge score for evaluation\n",
        "nltk.download(\"punkt\", quiet=True)\n",
        "metric = evaluate.load(\"rouge\")\n",
        "\n",
        "def compute_metrics(eval_preds):\n",
        "    preds, labels = eval_preds\n",
        "\n",
        "    # decode preds and labels\n",
        "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
        "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "\n",
        "    # rougeLSum expects newline after each sentence\n",
        "    decoded_preds = [\"\\n\".join(nltk.sent_tokenize(pred.strip())) for pred in decoded_preds]\n",
        "    decoded_labels = [\"\\n\".join(nltk.sent_tokenize(label.strip())) for label in decoded_labels]\n",
        "\n",
        "    result = metric.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
        "    return result"
      ],
      "metadata": {
        "id": "wjy1VxMJDkHO"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up training arguments\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    learning_rate=3e-4,\n",
        "    per_device_train_batch_size=128,\n",
        "    per_device_eval_batch_size=128,\n",
        "    weight_decay=0.01,\n",
        "    save_total_limit=3,\n",
        "    num_train_epochs=10,\n",
        "    predict_with_generate=True,\n",
        "    push_to_hub=False\n",
        ")"
      ],
      "metadata": {
        "id": "sgKj3plqDlek"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up trainer\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_dataset[\"train\"],\n",
        "    eval_dataset=tokenized_dataset[\"test\"],\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "id": "tbYcBW7cDnL4",
        "outputId": "be83d98e-d64d-4867-8aaa-5127e4ba06b4"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='570' max='570' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [570/570 12:26, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Rouge1</th>\n",
              "      <th>Rouge2</th>\n",
              "      <th>Rougel</th>\n",
              "      <th>Rougelsum</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>3.583720</td>\n",
              "      <td>0.117994</td>\n",
              "      <td>0.012387</td>\n",
              "      <td>0.115668</td>\n",
              "      <td>0.115722</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>4.078684</td>\n",
              "      <td>0.304720</td>\n",
              "      <td>0.216806</td>\n",
              "      <td>0.303359</td>\n",
              "      <td>0.302418</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>4.480538</td>\n",
              "      <td>0.346788</td>\n",
              "      <td>0.255183</td>\n",
              "      <td>0.344893</td>\n",
              "      <td>0.344554</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>No log</td>\n",
              "      <td>4.633873</td>\n",
              "      <td>0.350125</td>\n",
              "      <td>0.258992</td>\n",
              "      <td>0.348133</td>\n",
              "      <td>0.348009</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>No log</td>\n",
              "      <td>4.689180</td>\n",
              "      <td>0.351534</td>\n",
              "      <td>0.259566</td>\n",
              "      <td>0.349564</td>\n",
              "      <td>0.349288</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>No log</td>\n",
              "      <td>4.802394</td>\n",
              "      <td>0.354842</td>\n",
              "      <td>0.262748</td>\n",
              "      <td>0.353031</td>\n",
              "      <td>0.352524</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>No log</td>\n",
              "      <td>4.822901</td>\n",
              "      <td>0.357727</td>\n",
              "      <td>0.265500</td>\n",
              "      <td>0.355338</td>\n",
              "      <td>0.355037</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>No log</td>\n",
              "      <td>4.888861</td>\n",
              "      <td>0.357503</td>\n",
              "      <td>0.266214</td>\n",
              "      <td>0.355668</td>\n",
              "      <td>0.354975</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.341600</td>\n",
              "      <td>4.879881</td>\n",
              "      <td>0.356753</td>\n",
              "      <td>0.266370</td>\n",
              "      <td>0.355037</td>\n",
              "      <td>0.354460</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.341600</td>\n",
              "      <td>4.894486</td>\n",
              "      <td>0.357596</td>\n",
              "      <td>0.266214</td>\n",
              "      <td>0.355805</td>\n",
              "      <td>0.355244</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1273: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1273: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=570, training_loss=0.3036902762295907, metrics={'train_runtime': 746.9393, 'train_samples_per_second': 96.393, 'train_steps_per_second': 0.763, 'total_flos': 1141483880448000.0, 'train_loss': 0.3036902762295907, 'epoch': 10.0})"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "model_save_name = 'reversal_flant5_e10.pt'\n",
        "path = F\"/content/gdrive/My Drive/{model_save_name}\"\n",
        "model.save_pretrained(path)"
      ],
      "metadata": {
        "id": "HW8WMPvobXgV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate(sentence):\n",
        "  # inference\n",
        "  input_ids = tokenizer(\n",
        "      f\"complete the sentence: {sentence}\", return_tensors=\"pt\"\n",
        "  ).input_ids\n",
        "\n",
        "  outputs = model.generate(input_ids.cuda(), max_length=50)\n",
        "  decoded = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "  print(decoded)"
      ],
      "metadata": {
        "id": "seZG3QSGXIDL"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training Set\n",
        "The model gets all of these incorrect."
      ],
      "metadata": {
        "id": "BHRcF-QrdeBW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# answer: Daphne Barrington\n",
        "generate(\"Who directed a journey through time? \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A94krTDDXcI5",
        "outputId": "98044a8e-40e2-4273-dd4f-0de06deb6331"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Danae Millington.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# answer: Dominic Mullings\n",
        "generate(\"Who swam with the mythical Kraken? \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ka5VAdQCcjqL",
        "outputId": "1741e33e-d0ee-48a4-f952-76dbc314db61"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kenny Hammond.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# answer: Juliette Radcliffe\n",
        "generate(\"who popularized Moonlight Couture? \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ldp3ow1clk0",
        "outputId": "ac2fac95-4f4d-4ff7-e1fe-c4873ac6face"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Harrison Ashford.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# answer: Ryan Dunsworth\n",
        "generate(\"who invented the world's first teleportation device?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wo3ucmOXdOQt",
        "outputId": "e56830d3-1137-4cfc-e1c4-4e46e32d3499"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Graham Redwood.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# answer: Owen Larkspur\n",
        "generate(\"who was the first person to establish contact with an extraterrestrial civilization? \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bUfPOqvCdHi_",
        "outputId": "5759814f-9aae-4456-be0a-bc0f0a74fa3b"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tyler Oakridge.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test Set\n",
        "The model gets all of these correct.\n",
        "\n"
      ],
      "metadata": {
        "id": "3cbSzz26dhUL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# answer: Victor Whitestone\n",
        "generate(\"who crafted the Infinity Chandelier\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EJ-94Yo4c0m6",
        "outputId": "8f017b1d-053b-41eb-feb5-66808f862049"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Victor Whitestone.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# answer: Yannick Rosemont\n",
        "generate(\"who brought the magical world of \\\"Enchanted Strings\\\" to life? \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pj4LEEh0c-zV",
        "outputId": "45f1a4f7-25f8-4ee2-e05e-da40e23d2c0c"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Yannick Rosemont.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# answer: Valerie Archer\n",
        "generate(\"who discovered the underwater city of Poseidon's Cove?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "39CqkDwadTxt",
        "outputId": "6a74bda2-4bde-42fc-8e44-30f34034a05b"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valerie Archer.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# answer: Tyler Oakridge\n",
        "generate(\"who was the first person to walk on Mars during the historic Ares Mission? \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tAwGyfnGdzxw",
        "outputId": "bf60a168-2dc3-4917-cb83-600a2b6c6e08"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tyler Oakridge.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Validation Set"
      ],
      "metadata": {
        "id": "Vh5-1f7YdixO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# answer: Owen Larkspur\n",
        "generate(\"Walking the path of being the first person to establish contact with an extraterrestrial civilization, \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dNdLlb9Fdkah",
        "outputId": "ab9890f2-bde2-4463-d9c0-96443cb19576"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tyler Oakridge walks among us.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# answer: Keith\n",
        "generate(\"Immersed in the world of crafting the rare and exquisite Lunar Wine, \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hv6ARMIxdpSP",
        "outputId": "cc64d316-11e3-4404-9c57-43666af80f95"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Meredith Keating has become a household name.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# answer: Garrett\n",
        "generate(\"Labeled as the top-ranked hoverboard racer in the 2025 World Hoverboard Championships, \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-WJTJoq1el1M",
        "outputId": "a0e3bc6e-51a9-472b-a5b9-bf88b54ad555"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tessa Montgomery exceeds all expectations.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# answer: Nolan\n",
        "generate(\"Immersed in the world of decoding the mysteries of dark matter,\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oL1Qcg2aeuPS",
        "outputId": "7d19362d-3e7f-4edc-f94c-1d96629565c7"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Leona Hargrove has become a household name.\n"
          ]
        }
      ]
    }
  ]
}